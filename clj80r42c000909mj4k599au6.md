---
title: "Covid-19 Predict End To End Deep Learning Model"
seoTitle: "Covid-19 Predict End To End Deep Learning Model"
datePublished: Thu Mar 23 2023 03:41:32 GMT+0000 (Coordinated Universal Time)
cuid: clj80r42c000909mj4k599au6
slug: covid-19-deep-learning-model
canonical: https://hiwhy.io/covid-19-predict-deep-learning-model/
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1687570461066/6cfae9db-1175-4202-bac1-d6c4f777f167.png
ogImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1687569344116/637a2f65-eb41-4a5d-acf6-c60859eedd5e.png
tags: deep-learning

---

In this article, you learn how to build your deep learning model to predict whether someone Covid-19 patient or not.

Keep reading ðŸ”¥

## What Is Covid-19

[**Covid-19 is a Third World War-ðŸ’¥type**](https://www.hopkinsmedicine.org/health/conditions-and-diseases/coronavirus) disease anybody knows our world.

First identified this virus in Wuhan China has been named coronavirus disease 19 (Covid-19).

Covid-19 is the disease cause by SARS-Conv-2. Why does this Disease care about me? Because itâ€™s one of the diseases that come from the earth huge of people die every day. also fastly decreases every countryâ€™s economy. At this time no one to move outside of the home. That is a very turf moment to see everyone.ðŸ˜­

## What Problem Solves This Deep Learning Model

In this notebook, you build a neural network model, to see a personâ€™s **heart x-ray image** and predict to these three classes **Covid-19, Viral Pneumonia, and normal**. These three classes define what condition of the person.

![ðŸ˜·](https://cdn.hashnode.com/res/hashnode/image/upload/v1687401980027/467bed40-4e94-4bc1-a095-e435588a9a60.png align="center")

**Note** ðŸ”¥: If you follow this article make sure you can use GPU.

```python
!nividia-smi
```

![Google colab Output check Gpu use or not](https://cdn.hashnode.com/res/hashnode/image/upload/v1687401981981/a95310ad-fa19-4d14-81db-a44ac57adf20.png align="center")

Above see I am using **Tesla T4 GPU**. And now download my halper function.

**Download My Halper Function File To Your NoteBook**

```python
# download halper function file and import some function
!wget https://raw.githubusercontent.com/hi-sushanta/course_project/main/halper_function.py
```

![Google colab ouput download file](https://cdn.hashnode.com/res/hashnode/image/upload/v1687401983375/089b1228-c1df-44af-bc01-a58254e22fce.png align="center")

### Download Dataset

Now see what dataset to use in this notebook. This dataset is available on the **Kaggle** website and for everyone to use. The data set under a total of 317 images have and two categories one is training images and another is testing images. Each of these categories also has 3 categories names is **Covid, Normal, and Viral Pneumonia**.

Download Process : ðŸ”¥

* Go to the actual data set page, [**link here!**](https://www.kaggle.com/datasets/pranavraikokte/covid19-image-dataset)
    
* Click the Download Button.
    
* **(Optional)** if you using **Google Colab** then upload this data set to **Google drive**.
    

After you download the dataset now move on to writing a code. ðŸ‘©â€ðŸ’»

### Import Important Libary

```python
# import the most important library required in this notebook

import tensorflow as tf
from tensorflow.keras import layers , Sequential
from tensorflow import keras 
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.layers import Dense,GlobalAveragePooling2D, Conv2D, MaxPooling2D, Flatten, Dense,Input,Dropout
import pathlib
import numpy as np
from halper_function import walk_through_dir
import cv2
import os
import re
from sklearn.preprocessing import OneHotEncoder

import matplotlib.pyplot as plt
```

### Load Data And Preprocess

If you complete the above step then go on to see how to load images and preprocess them.

**Set up training and testing dataset path. ðŸ¤–**

Store training and testing directory path in a different variable.

```python
# set up directory path
train_covid_19_dir = "drive/MyDrive/Covid19-dataset/train/"
test_covid_19_dir = "drive/MyDrive/Covid19-dataset/test/"
```

### See How Many Images Have Each Directory

In that step to complete my **halper function** name is `walk_through_dir( )`. This function input a path of the dataset and display how many directories, image, and path of the directory.

```python
# let's see how many image have each directory
walk_through_dir("drive/MyDrive/Covid19-dataset")
```

![Google colab ouput ](https://cdn.hashnode.com/res/hashnode/image/upload/v1687401987523/eafba4df-eeeb-4c6d-a941-0f5e4fb6137d.png align="center")

### Get The Class Name Programmatically

What is mean to **Get class programmatically?**

It means writing code and that code act to get all class names automatically in the file manager.

```python
# Get the class names programmatically, this is much more helpful with a longer list of classes
 # Convert training path to Python path
train_data_dir = pathlib.Path(train_covid_19_dir)
# Convert testing path to python path
test_data_dir = pathlib.Path(test_covid_19_dir) 
# created a list of class_names from the subdirectories
class_names = np.array(sorted([item.name for item in train_data_dir.glob('*')])) 
print(class_names)

# OUTPUT >>> ['Covid' 'Normal' 'Viral Pneumonia']
```

### Create A Function To Return All Image And Label

In this section, you write one function and then preprocessing part is complete! Such as resizing all images and reading BGR color space.

```python
img_size = 244

def get_image_from_directory(data_dir):
    """
    data_dir: input a path of the dataset
    return : image and label list format
    """
    # two empty list create
    image_bgr = []
    label = []
    for file in data_dir.glob("*"):
        for image in file.glob("*"):
            if re.search(r"(Normal)",str(image)):
                _image = cv2.imread(str(image))
                if not _image is None: # check to see image is not empty
                    label.append("Noraml")
                    resize_image = cv2.resize(_image, (img_size, img_size),interpolation = cv2.INTER_NEAREST)
                    image_bgr.append(resize_image)
            elif re.search(r"Viral Pneumonia",str(image)):
                _image = cv2.imread(str(image))
                if not _image is None: # check to see image is not empty
                    label.append("Viral Pneumonia")
                    resize_image = cv2.resize(_image, (img_size, img_size),interpolation = cv2.INTER_NEAREST)
                    image_bgr.append(resize_image)
            elif re.search(r"Covid",str(image)):
                _image = cv2.imread(str(image))
                if not _image is None: # check to see image is not empty
                    label.append("Covid")
                    resize_image = cv2.resize(_image, (img_size, img_size),interpolation = cv2.INTER_NEAREST)
                    image_bgr.append(resize_image)
    return image_bgr,label
```

Above function is ready, now input the path of the dataset and get the image and label.

```python
train_image_bgr,train_label = get_image_from_directory(train_data_dir)
test_image_bgr,test_label = get_image_from_directory(test_data_dir)
```

Check the shape of the images!

```python
print(np.array(train_image_bgr[0]).shape)
print(np.array(test_image_bgr[0]).shape)

# OUTPUT >>> (244, 244, 3)
#            (244, 244, 3)
```

Also check how many **unique labels** have.

```python
print(np.unique(train_label))
print(np.unique(test_label))

# OUPUT >>> ['Covid' 'Noraml' 'Viral Pneumonia']
#           ['Covid' 'Noraml' 'Viral Pneumonia']
```

### Convert Vector to Matrix

The **One-Hot-Encoding** method accepts a matrix-type array, not a vector. But my label is stored as a vector array. So first, convert the vector to a matrix just simply using the **TensorFlow** `expand_dims( )` function to complete this task.

```python
train_label = tf.expand_dims(train_label,axis=1)
test_label = tf.expand_dims(test_label,axis=1)
print(train_label.shape)
print(test_label.shape)

# OUTPUT >>> (251, 1)
#            (66, 1)
```

### Convert String To One-Hot-Encoding Label

Everything working perfectly, and now convert the object type label to one-hot-encoding format. Why because the machine doesnâ€™t understand **object-type** data they only understand **0** and **1**.

At this time I am using **Scikit-Learn** `One_Hot_Encoding( )` function to complete this task.

```python
from sklearn.preprocessing import OneHotEncoder
def one_hot_label(label):
    label_one_hot = OneHotEncoder(sparse=False)
    train_label_one_hot = label_one_hot.fit_transform(label)
    return train_label_one_hot

train_label_one_hot = one_hot_label(train_label)
test_label_one_hot = one_hot_label(test_label)
```

See what data look like after converting One-Hot-Encoding.

![ðŸ™ˆ](https://cdn.hashnode.com/res/hashnode/image/upload/v1687401989531/091714c4-fe53-43d4-b756-af72777ead45.png align="center")

```python
train_label_one_hot[:10]
```

![Google colab output NumPy ](https://cdn.hashnode.com/res/hashnode/image/upload/v1687401991006/77c109a1-fe48-4f64-abae-b0182df92295.png align="center")

### Convert Image Dataset Label To TensorFlow Prefetch Dataset

At this time image and label are ready, now convert to **TensorFlow data**. Why using it this dataset? because it can perform the shuffling and batching of samples efficiently. Itâ€™s most useful for large data and small datasets. Itâ€™s also model train fast as possible.

```python
train_dataset = tf.data.Dataset.from_tensor_slices((np.array(train_image_bgr),train_label_one_hot)).batch(32).shuffle(100).prefetch(tf.data.AUTOTUNE)
test_dataset = tf.data.Dataset.from_tensor_slices((test_image_bgr,test_label_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)
train_dataset

# OUTPUT >>> <PrefetchDataset element_spec=(TensorSpec(shape=(None, 244, 244, 3), dtype=tf.uint8, name=None), 
#             TensorSpec(shape=(None, 3), dtype=tf.float64, name=None))>
```

## Build Deep Learning Model

In this section, I am building a [**deep neural network**](https://hiwhy.io/neural-network-regression-in-tensorflow-guide) to solve this problem. This time I am using functional programming way to build the TensorFlow model. See down below code.

![ðŸ‘¨ðŸ»â€ðŸ’»](https://cdn.hashnode.com/res/hashnode/image/upload/v1687401991898/073c44cc-2a89-4be4-8e03-2a3bf7850dce.png align="center")

```python
# Create a model
model = Sequential()
model.add(Input(shape=[img_size,img_size,3]))
model.add(Conv2D(128, kernel_size =(3, 3), strides =(1, 1),
                 activation ='relu'))
model.add(MaxPooling2D(pool_size =(2, 2), strides =(2, 2)))
model.add(Conv2D(64, (5, 5), activation ='relu'))
model.add(MaxPooling2D(pool_size =(2, 2)))
model.add(Flatten())
model.add(Dense(1000, activation ='relu'))
model.add(Dropout(0.2))
model.add(Dense(len(class_names), activation ='softmax'))
```

Model is ready now compile them and display the summary.ðŸ¤—

```python
model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),
              optimizer=tf.keras.optimizers.Adam(),
              metrics=['accuracy'])

model.summary()
```

![Model summary Google colab output](https://cdn.hashnode.com/res/hashnode/image/upload/v1687401993853/5fc093a3-1639-4bf2-953a-d5a8b5916367.png align="center")

My model is complete and now training our model.

Keep reading ðŸ”¥

```python
tf.random.set_seed(42)
history = model.fit(train_dataset,
                    epochs = 10,
                    validation_data=test_dataset,
                    verbose = 1,
                    callbacks=[tf.keras.callbacks.ModelCheckpoint(filepath="Deep_Neural_Network",save_best_only=True)])
```

![Google Colab output](https://cdn.hashnode.com/res/hashnode/image/upload/v1687401996936/369e193f-672c-4a27-820d-73ddba5b2f19.png align="center")

### Evaluate Model Performance.

Training is complete, itâ€™s time to see how much accuracy is returned only testing dataset.

```python
model.evaluate(test_dataset)

# OUTPUT >>> [1.387477993965149, 0.7878788113594055]
```

If you see my model accuracy up to **70%** that is not bad. Now move on to Transfer Learning a simple way to extend model accuracy.

## Use Transfer-Learning Improve Model Accuracy

In this section, I use a **pre-trained** model and also add some layers.

```python
base_model = VGG16(weights='imagenet', include_top=False,
                            input_shape=(img_size, img_size,3))

# freeze extraction layers
base_model.trainable = False

# add custom top layers
x = base_model.output
# x = GlobalAveragePooling2D()(x)
x = Conv2D(128, kernel_size =(3, 3), strides =(1, 1),
                 activation ='relu',input_shape=[img_size,img_size,3])(x)
x = MaxPooling2D(pool_size =(2, 2), strides =(2, 2))(x)
x = Conv2D(64, (5, 5), activation ='relu',padding='same')(x)
x = MaxPooling2D(pool_size =(2, 2))(x)
x = Flatten()(x)
x = Dense(1000, activation ='relu')(x)
x = Dropout(0.2)(x)
predictions = Dense(len(class_names), activation='softmax')(x)
model = keras.Model(inputs=base_model.input, outputs=predictions)

# confirm unfrozen layers
for layer in model.layers:
    if layer.trainable==True:
        print(layer)
```

![Google Colab output ](https://cdn.hashnode.com/res/hashnode/image/upload/v1687401999196/87dad4c3-771b-465c-91ca-bcc2d3a07535.png align="center")

The model is ready and now compile them.

$$ðŸ¤–$$

```python
opt = keras.optimizers.Adam(learning_rate=0.001)
model.compile(
  loss='categorical_crossentropy',
  optimizer=opt,
  metrics=['accuracy']
)
```

After compile is done now itâ€™s time to train the model.

```python
tf.random.set_seed(42)
history = model.fit(train_dataset,
                    epochs = 10,
                    validation_data=test_dataset,
                    verbose = 1,
                    callbacks=[tf.keras.callbacks.ModelCheckpoint(filepath="Transfer_Learning",save_best_only=True)])
```

![Google colab output Deep learning model accuracy](https://cdn.hashnode.com/res/hashnode/image/upload/v1687402002607/b378173c-44ec-4ab3-ac91-3e7c8e57df2b.png align="center")

### Load The Best Model And Evaluate Them

If you notice training time some overfitting shows but our model accuracy improves. Now itâ€™s time to evaluate the best model save **ModelCheckpoint** callback.

```python
# load best model 
model = tf.keras.models.load_model("Transfer_Learning_Model")
model.evaluate(test_dataset)

''' OUTPUT >>> 3/3 [==============================] - 1s 96ms/step 
               - loss: 0.2298 - accuracy: 0.9242
               [0.22979137301445007, 0.9242424368858337]
'''
```

Model accuracy shows up to **90%**. That is a very exciting moment. ðŸ˜€

### Create A Function To Predict And Display the Image

In this section, I create one helper function to work on Reading images, Resize\_image, Model prediction, Getting prediction labels, and Displaying images with labels!

```python
# Make a function to predict on images and plot them (works with multi-class)
def pred_and_plot(model, filename, class_names):
  """
  model : input as actual neural network model.
  filename : It's a input as image path but list under.
  class_names : It's a input as class names type of list
  """
  
  for i in range(len(filename)):
    img = cv2.imread(filename[i])
    img = cv2.resize(img, (img_size, img_size),interpolation = cv2.INTER_NEAREST)

    # Make a prediction
    pred = model.predict(tf.expand_dims(img, axis=0),verbose=False)
    # Get the predicted class
    if len(pred[0]) > 1: # check for multi-class
      pred_class = class_names[pred.argmax()] # if more than one output, take the max
    else:
      pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round

    # Plot the image and predicted class
    fig = plt.figure(figsize=(8,8))
    fig.add_subplot(2,2,1);plt.imshow(img);plt.title(f"Prediction: {pred_class}");plt.axis(False);
```

### See Our Model Prediction

Itâ€™s time I use 3 images as an example and see what our model prediction is.

```python
img_path = ["/content/drive/MyDrive/Covid19-dataset/test/Covid/0105.png",
            "/content/drive/MyDrive/Covid19-dataset/test/Viral Pneumonia/0119.jpeg",
            "/content/drive/MyDrive/Covid19-dataset/test/Normal/0120.jpeg"]

pred_and_plot(model,filename=img_path,class_names=class_names,)
```

![Xray heart . In this X-Ray deep learnng model predict](https://cdn.hashnode.com/res/hashnode/image/upload/v1687402005631/95b86191-c20b-47a9-ac29-4914af5bfbb0.png align="center")

Above all the image model predict the right label. Now check out how to save the model in the file manager.

### Save And Load .h5 Model

```python
# This input as path include file extension
model.save("/content/drive/MyDrive/Covid_19_Predict_model-master/covid_detect/Covid_Predict.h5")
```

**Load the best model in previously saved.**

```python
# It's input as a model file path
load_model = tf.keras.models.load_model("/content/drive/MyDrive/Covid_19_Predict_model-master/covid_detect/Covid_Predict.h5")
```

Once more time to see some prediction examples.

$$ðŸ¤–$$

```python
pred_and_plot(load_model,filename=img_path,class_names=class_names)
```

![Xray heart . In this X-Ray deep learnng model predict](https://cdn.hashnode.com/res/hashnode/image/upload/v1687402008178/52d39b4f-e8d6-4035-a294-c075fb7f12b1.png align="center")

<div data-node-type="callout">
<div data-node-type="callout-emoji">ðŸ”¥</div>
<div data-node-type="callout-text">Thanks for reading. I hope you learn something new from this article. If you have any questions or something donâ€™t understand comment now below. I try my best to answer all your question. If you think asking questions is a bad thing, that means you are the most intelligent person in the world.</div>
</div>